AWSTemplateFormatVersion: 2010-09-09
Description: CloudFormation sub-template for Auto-scaling group deployment
Parameters:
  Env:
    Type: String
    Description: The environment you're deploying to.
  AssignPublicIP:
    AllowedValues:
      - 'true'
      - 'false'
    ConstraintDescription: Either true or false
    Default: 'true'
    Description: Allociate a public IP address to each instance
    Type: String
  BootDiskSize:
    ConstraintDescription: Deployment supports 8 to 128 GB for boot volumes
    Default: '24'
    Description: Allocated EBS storage for boot disk
    MaxValue: '128'
    MinValue: '8'
    Type: Number
  ClusterInfoHandle:
    Description: ''
    Type: String
  ClusterName:
    AllowedPattern: '([A-Za-z]{1}[0-9A-Za-z_-]*)'
    ConstraintDescription: The ClusterName value must be alphanumeric
    Default: awsmk
    Description: Confluent Cluster ID
    Type: String
  ConfluentEdition:
    AllowedValues:
      - Confluent Open Source
      - Confluent Enterprise
    Default: Confluent Enterprise
    Description: Confluent Software Edition
    Type: String
  ConfluentSecurity:
    AllowedValues:
      - Disabled
      - Enabled
    Default: Disabled
    Description: Enable strong authentication for cluster access
    Type: String
  ConfluentVersion:
    ConstraintDescription: Supported versions of Confluent Platform within AWS Marketplace
    Default: 3.3.1
    Description: Confluent Software Version
    Type: String
  ConnectorURLs:
    Default: ''
    Description: >-
      Public locations (comma-separated list) from which to download additional
      Kafka Connect jars (eg https://s3.amazonaws.com/connector-bucket/dynamo)
    Type: String
  InstanceProfile:
    Description: IAM Profile for the deployment
    Type: String
  InstanceRole:
    Description: >-
      IAM Role for the deployment. The EC2 instances must be able to access this
      role using the instance profile.
    Type: String
  KeyPairName:
    Description: >-
      Name of an existing EC2 key pair within the AWS region; all instances will
      launch with this key pair
    Type: 'AWS::EC2::KeyPair::KeyName'
  LinuxOSAMI:
    AllowedValues:
      - CentOS-7-HVM
      - Ubuntu-Server-16.04-LTS-HVM
      - Amazon-Linux-HVM
    ConstraintDescription: Supported versions of Linux AMIs for Confluent deployments
    Default: CentOS-7-HVM
    Description: Operating system AMI for cluster instances
    Type: String
  NodeDesignation:
    Default: unspecified
    Description: Tag for deployed instances
    Type: String
  NodeType:
    Default: unspecified
    Description: Tag for deployed instances to differentiate producer and consumer nodes
    Type: String
  LogGroupName:
    Default: "/dev/groundstation/messages"
    Description: Log group name in Cloudwatch where the agent logs from consumer are stored
    Type: String 
  KafkaTopicReplicationFactor:
    Default: 1
    Description: Kafka Topic Replication Factor
    Type: Number
  KafkaTopicPartitions:
    Default: 1
    Description: Kafka Topic Partitions
    Type: Number
  KafkaTopic:
    Default: groundstation
    Description: Kafka Topic
    Type: String
  NodeInstanceType:
    AllowedValues:
      - t3.micro
      - t2.medium
      - t2.large
      - m3.medium
      - m3.large
      - m3.xlarge
      - m3.2xlarge
      - m4.large
      - m4.xlarge
      - m4.2xlarge
      - m4.4xlarge
      - c3.xlarge
      - c3.2xlarge
      - c3.4xlarge
      - d2.xlarge
      - d2.2xlarge
      - d2.4xlarge
      - d2.8xlarge
      - i2.xlarge
      - i2.2xlarge
    ConstraintDescription: Must be a valid EC2 instance type.
    Default: d2.xlarge
    Description: Instance Type
    Type: String
  NodeSecurityGroup:
    Description: >-
      Comma separated list of security groups for the members of the cluster
      (e.g. sg-7f16e910,sg-4be93ca2); The security groups must be in the same
      VPC as the subnets
    Type: 'List<AWS::EC2::SecurityGroup::Id>'
  NodeSpotPrice:
    AllowedPattern: '([0-9]{1}[.]{1}[0-9]{2})'
    ConstraintDescription: Must be decimal numeric value
    Default: '0.00'
    Description: >-
      Spot Price to bid for requested instances (0.00 will result in using
      on-demand instances)
    Type: String
  NumNodes:
    Default: '3'
    Description: Number of Nodes in Auto-scaling Group
    MaxValue: '9'
    MinValue: '1'
    Type: Number
  ParentStackName:
    Description: Wrapper stack for this deployment
    Type: String
  PersistentStorage:
    ConstraintDescription: No more than 4000 GiB per device (16 TB per node).
    Default: '0'
    Description: >-
      Allocated EBS storage for each block device (in GiB; 4 devs per node); 0
      indicates ephemeral storage only
    MaxValue: '4000'
    MinValue: '0'
    Type: Number
  PersistentStorageType:
    AllowedValues:
      - ''
      - gp2
      - sc1
      - st1
    Default: ''
    Description: >-
      EBS volume type (blank indicates default type for ami/region).  sc1 and
      st1 volumes must be at least 500 GiB in size.
    Type: String
  QSS3BucketName:
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    ConstraintDescription: >-
      Quick Start bucket name can include numbers, lowercase letters, uppercase
      letters, and hyphens (-). It cannot start or end with a hyphen (-).
    Default: aws-quickstart
    Description: >-
      S3 bucket name for the Quick Start assets. Quick Start bucket name can
      include numbers, lowercase letters, uppercase letters, and hyphens (-). It
      cannot start or end with a hyphen (-).
    Type: String
  QSS3KeyPrefix:
    AllowedPattern: '^[0-9a-zA-Z-/]*$'
    ConstraintDescription: >-
      Quick Start key prefix can include numbers, lowercase letters, uppercase
      letters, hyphens (-), and forward slash (/).
    Default: quickstart-confluent-kafka/
    Description: >-
      S3 key prefix for the Quick Start assets. Quick Start key prefix can
      include numbers, lowercase letters, uppercase letters, hyphens (-), and
      forward slash (/).
    Type: String
  SubnetID:
    Description: >-
      Comma separated list of VPC subnet IDs for the cluster deployment (e.g.
      subnet-4b8d329f,subnet-bd73afc8); VPC must exist with proper configuration
      for Confluent cluster access (internal and external)and the subnets must
      be in the same VPC as the security groups
    Type: 'List<AWS::EC2::Subnet::Id>'
Mappings:
  AWSAMIRegionMap:
    AMI:
      AMZNLINUXHVM: amzn-ami-hvm-2018.03.0.20190611-x86_64-gp2
      CENTOS7HVM: >-
        CentOS Linux 7 x86_64 HVM EBS ENA
        1901_01-0722b432-8459-49b6-9b90-79b42624d25d-ami-05713873c6794f575.4
      US1604HVM: ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-20190628
    ap-northeast-1:
      AMZNLINUXHVM: ami-02ddf94e5edc8e904
      CENTOS7HVM: ami-045f38c93733dd48d
      US1604HVM: ami-03344c819e1ac354d
    ap-northeast-2:
      AMZNLINUXHVM: ami-0ecd78c22823e02ef
      CENTOS7HVM: ami-06cf2a72dadf92410
      US1604HVM: ami-0c5a717974f63b04c
    ap-south-1:
      AMZNLINUXHVM: ami-05695932c5299858a
      CENTOS7HVM: ami-02e60be79e78fef21
      US1604HVM: ami-0c28d7c6dd94fb3a7
    ap-southeast-1:
      AMZNLINUXHVM: ami-043afc2b8b6cfba5c
      CENTOS7HVM: ami-0b4dd9d65556cac22
      US1604HVM: ami-0ca13b3dabeb6c66d
    ap-southeast-2:
      AMZNLINUXHVM: ami-01393ce9a3ca55d67
      CENTOS7HVM: ami-08bd00d7713a39e7d
      US1604HVM: ami-02d7e25c1cfdd5695
    ca-central-1:
      AMZNLINUXHVM: ami-0fa94ecf2fef3420b
      CENTOS7HVM: ami-033e6106180a626d0
      US1604HVM: ami-0f06e521718460abf
    eu-central-1:
      AMZNLINUXHVM: ami-0ba441bdd9e494102
      CENTOS7HVM: ami-04cf43aca3e6f3de3
      US1604HVM: ami-03d8059563982d7b0
    eu-west-1:
      AMZNLINUXHVM: ami-0e61341fa75fcaa18
      CENTOS7HVM: ami-0ff760d16d9497662
      US1604HVM: ami-0f630a3f40b1eb0b8
    eu-west-2:
      AMZNLINUXHVM: ami-050b8344d77081f4b
      CENTOS7HVM: ami-0eab3a90fc693af19
      US1604HVM: ami-0a590332f9f499197
    sa-east-1:
      AMZNLINUXHVM: ami-05b7dbc290217250d
      CENTOS7HVM: ami-0b8d86d4bf91850af
      US1604HVM: ami-0a16d0952a2a7b0ce
    us-east-1:
      AMZNLINUXHVM: ami-0e2ff28bfb72a4e45
      CENTOS7HVM: ami-02eac2c0129f6376b
      US1604HVM: ami-08bc77a2c7eb2b1da
    us-east-2:
      AMZNLINUXHVM: ami-0998bf58313ab53da
      CENTOS7HVM: ami-0f2b4fc905b0bd1f1
      US1604HVM: ami-08cec7c429219e339
    us-west-1:
      AMZNLINUXHVM: ami-021bb9f371690f97a
      CENTOS7HVM: ami-074e2d6769f445be5
      US1604HVM: ami-094f0176b0d009d9f
    us-west-2:
      AMZNLINUXHVM: ami-079f731edfe27c29c
      CENTOS7HVM: ami-01ed306a12b7d1c96
      US1604HVM: ami-02d0ea44ae3fe9561
  LinuxAMINameMap:
    Amazon-Linux-HVM:
      Code: AMZNLINUXHVM
    CentOS-7-HVM:
      Code: CENTOS7HVM
    Ubuntu-Server-16.04-LTS-HVM:
      Code: US1604HVM
  Linux2BootDisk:
    Amazon-Linux-HVM:
      BootDisk: /dev/xvda
    CentOS-7-HVM:
      BootDisk: /dev/sda1
    Ubuntu-Server-16.04-LTS-HVM:
      BootDisk: /dev/sda1
Conditions:
  EphemeralStorage: !Equals 
    - !Ref PersistentStorage
    - '0'
  OnDemandInstances: !Equals 
    - !Ref NodeSpotPrice
    - '0.00'
  UseDefaultVT: !Equals 
    - !Ref PersistentStorageType
    - ''
Resources:
  NodesReadyHandle:
    Type: 'AWS::CloudFormation::WaitConditionHandle'
  NodesReadyCondition:
    Type: 'AWS::CloudFormation::WaitCondition'
    Properties:
      Handle: !Ref NodesReadyHandle
      Timeout: '2400'
      Count: !Ref NumNodes
  Nodes:
    Type: 'AWS::AutoScaling::AutoScalingGroup'
    Properties:
      VPCZoneIdentifier: !Ref SubnetID
      LaunchConfigurationName: !Ref NodeLaunchConfig
      MinSize: 0
      MaxSize: !Ref NumNodes
      DesiredCapacity: !Ref NumNodes
    CreationPolicy:
      ResourceSignal:
        Count: !Ref NumNodes
        Timeout: PT30M
  NodeLaunchConfig:
    Type: 'AWS::AutoScaling::LaunchConfiguration'
    Metadata:
      'AWS::CloudFormation::Authentication':
        S3AccessCreds:
          type: S3
          roleName: !Ref InstanceRole
          buckets:
            - !Ref QSS3BucketName
      'AWS::CloudFormation::Init':
        config:
          files:
            /tmp/sbin/compute-heap-opts:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/compute-heap-opts
              mode: '000755'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/sbin/cp-deploy.sh:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/cp-deploy.sh
              mode: '000755'
              owner: root
              group: root
            /tmp/sbin/cp-install.sh:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/cp-install.sh
              mode: '000755'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/sbin/cp-retrieve-connect-jars.sh:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/cp-retrieve-connect-jars.sh
              mode: '000755'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/sbin/cp-retrieve-scripts.sh:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/cp-retrieve-scripts.sh
              mode: '000755'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/sbin/gen-cluster-hosts.sh:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/gen-cluster-hosts.sh
              mode: '000755'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/sbin/prep-cp-instance.sh:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/prep-cp-instance.sh
              mode: '000755'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/sbin/prepare-disks.sh:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/prepare-disks.sh
              mode: '000755'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/sbin/post-cp-info.sh:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/post-cp-info.sh
              mode: '000755'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/sbin/wait-for-child-resource.sh:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/wait-for-child-resource.sh
              mode: '000755'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/sbin/wait-for-resource.sh:
              source: !Sub >-
                https://s3-${AWS::Region}.amazonaws.com/${QSS3BucketName}/${QSS3KeyPrefix}scripts/wait-for-resource.sh
              mode: '000755'
              owner: root
              group: root
              authentication: S3AccessCreds
    Properties:
      BlockDeviceMappings: !If 
        - EphemeralStorage
        - - DeviceName: !FindInMap 
              - Linux2BootDisk
              - !Ref LinuxOSAMI
              - BootDisk
            Ebs:
              VolumeSize: !Ref BootDiskSize
              DeleteOnTermination: 'True'
          - DeviceName: /dev/sdb
            VirtualName: ephemeral0
          - DeviceName: /dev/sdc
            VirtualName: ephemeral1
          - DeviceName: /dev/sdd
            VirtualName: ephemeral2
          - DeviceName: /dev/sde
            VirtualName: ephemeral3
          - DeviceName: /dev/sdf
            VirtualName: ephemeral4
          - DeviceName: /dev/sdg
            VirtualName: ephemeral5
          - DeviceName: /dev/sdh
            VirtualName: ephemeral6
          - DeviceName: /dev/sdi
            VirtualName: ephemeral7
          - DeviceName: /dev/sdj
            VirtualName: ephemeral8
          - DeviceName: /dev/sdk
            VirtualName: ephemeral9
          - DeviceName: /dev/sdl
            VirtualName: ephemeral10
          - DeviceName: /dev/sdm
            VirtualName: ephemeral11
        - - DeviceName: !FindInMap 
              - Linux2BootDisk
              - !Ref LinuxOSAMI
              - BootDisk
            Ebs:
              VolumeSize: !Ref BootDiskSize
              DeleteOnTermination: 'True'
          - DeviceName: /dev/sdb
            Ebs:
              VolumeSize: !Ref PersistentStorage
              VolumeType: !If 
                - UseDefaultVT
                - !Ref 'AWS::NoValue'
                - !Ref PersistentStorageType
              DeleteOnTermination: 'True'
          - DeviceName: /dev/sdc
            Ebs:
              VolumeSize: !Ref PersistentStorage
              VolumeType: !If 
                - UseDefaultVT
                - !Ref 'AWS::NoValue'
                - !Ref PersistentStorageType
              DeleteOnTermination: 'True'
          - DeviceName: /dev/sdd
            Ebs:
              VolumeSize: !Ref PersistentStorage
              VolumeType: !If 
                - UseDefaultVT
                - !Ref 'AWS::NoValue'
                - !Ref PersistentStorageType
              DeleteOnTermination: 'True'
          - DeviceName: /dev/sde
            Ebs:
              VolumeSize: !Ref PersistentStorage
              VolumeType: !If 
                - UseDefaultVT
                - !Ref 'AWS::NoValue'
                - !Ref PersistentStorageType
              DeleteOnTermination: 'True'
      ImageId: !FindInMap 
        - AWSAMIRegionMap
        - !Ref 'AWS::Region'
        - !FindInMap 
          - LinuxAMINameMap
          - !Ref LinuxOSAMI
          - Code
      SecurityGroups: !Ref NodeSecurityGroup
      InstanceType: !Ref NodeInstanceType
      SpotPrice: !If 
        - OnDemandInstances
        - !Ref 'AWS::NoValue'
        - !Ref NodeSpotPrice
      KeyName: !Ref KeyPairName
      AssociatePublicIpAddress: !Ref AssignPublicIP
      IamInstanceProfile: !Ref InstanceProfile
      UserData: !Base64 
        'Fn::Join':
          - ''
          - - |
              #!/bin/bash
            - |+

            - |
              function error_exit
            - |
              {
            - ' cfn-signal -e 1 --stack '
            - !Ref 'AWS::StackName'
            - ' --region '
            - !Ref 'AWS::Region'
            - |2
               --resource Nodes
            - |2
               exit 1
            - |
              }
            - |+

            - |
              PATH=$PATH:/usr/local/bin 
            - |+

            - |
              ##Yum and Apt repo update
            - |
              [ `which yum` ] && yum install -y epel-release 
            - |
              [ `which apt-get` ] && apt-get -y update 
            - |
              ## Install core O/S packages
            - |
              if [ ! -f /usr/bin/sshpass ] ; then 
            - |2
                [ `which yum` ] && yum install -y sshpass 
            - |2
                [ `which apt-get` ] && apt-get -y install sshpass 
            - |
              fi 
            - |+

            - |
              which pip &> /dev/null 
            - |
              if [ $? -ne 0 ] ; then 
            - |2
                [ `which yum` ] && yum install -y python-pip
            - |2
                [ `which apt-get` ] && apt-get -y install python-pip
            - |
              fi 
            - |
              python -m pip install --upgrade pip
            - |
              python -m pip install awscli --ignore-installed six
            - |+

            - |
              ## Install and Update CloudFormation
            - >
              easy_install
              https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz
            - |+

            - |
              ## Signal that the node is up
            - 'cfn-signal -e 0 --stack '
            - !Ref 'AWS::StackName'
            - ' --region '
            - !Ref 'AWS::Region'
            - |2
               --resource Nodes
            - |+

            - |
              ## Save off other cluster details in prep for configuration
            - 'echo '
            - !Ref ClusterName
            - |2
               > /tmp/clustername
            - 'echo '
            - !Ref ConfluentEdition
            - |2
               > /tmp/cedition
            - 'echo '
            - !Ref ConfluentSecurity
            - |2
               > /tmp/csecurity
            - '[ "'
            - !Ref ConfluentSecurity
            - |
              " = 'Disabled' ] && rm /tmp/csecurity
            - 'echo '
            - !Ref ConfluentVersion
            - |2
               > /tmp/cversion
            - |+

            - |
              ## Retrieve scripts to deploy Confluent on the instances 
            - |
              ##  cfn-init downloads everything 
            - |
              ##  and then we're off to the races 
            - 'cfn-init -v '
            - '         --stack '
            - !Ref 'AWS::StackName'
            - '         --resource NodeLaunchConfig '
            - '         --region '
            - !Ref 'AWS::Region'
            - |+

            - |
              AMI_SBIN=/tmp/sbin 
            - |+

            - |
              ## Prepare the instance 
            - |
              $AMI_SBIN/prep-cp-instance.sh 
            - |
              . $AMI_SBIN/prepare-disks.sh 
            - |+

            - |
              ## Wait for all nodes to come on-line
            - '$AMI_SBIN/wait-for-child-resource.sh '
            - !Ref ParentStackName
            - |2
               ZookeeperStack Nodes
            - '$AMI_SBIN/wait-for-child-resource.sh '
            - !Ref ParentStackName
            - |2
               BrokerStack Nodes
            - '$AMI_SBIN/wait-for-child-resource.sh '
            - !Ref ParentStackName
            - |2
               WorkerStack Nodes
            - |+

            - |
              ## Now find the private IP addresses of all deployed nodes
            - |
              ##   (generating /tmp/cphosts and /tmp/<role> files)
            - '$AMI_SBIN/gen-cluster-hosts.sh '
            - !Ref ParentStackName
            - |+

            - |+

            - |
              ## Tag the instance (now that we're sure of launch index)
            - >
              ##   NOTE: ami_launch_index is correct only within a single
              subnet)
            - >
              instance_id=$(curl -f
              http://169.254.169.254/latest/meta-data/instance-id)
            - >
              ami_launch_index=$(curl -f
              http://169.254.169.254/latest/meta-data/ami-launch-index)
            - launch_node=$(grep -w `hostname -s` /tmp/
            - !Ref NodeDesignation
            - |
              s | awk '{print $2}')
            - |
              if [ -n "$launch_node" ] ; then
            - |2
                launch_index=${launch_node#*NODE}
            - |
              else
            - |2
                launch_index=${ami_launch_index}
            - |
              fi
            - |
              if [ -n "$instance_id" ] ; then
            - '  instance_tag='
            - !Ref ClusterName
            - '-'
            - !Ref NodeType
            - |
              -${launch_index}
            - '  aws ec2 create-tags'
            - ' --region '
            - !Ref 'AWS::Region'
            - |2
               --resources $instance_id --tags Key=Name,Value=$instance_tag
            - |
              fi
            - |
              ## Run the steps to install the software, 
            - |
              ## then configure and start the services 
            - |
              $AMI_SBIN/cp-install.sh 2> /tmp/cp-install.err 
            - |
              $AMI_SBIN/cp-deploy.sh 2> /tmp/cp-deploy.err 
            - |+

            - CONNECTOR_URLS=
            - !Ref ConnectorURLs
            - |2
               
            - |
              if [ -n "$CONNECTOR_URLS" ] ; then 
            - |2
                for csrc in ${CONNECTOR_URLS//,/ } ; do 
            - |2
                  $AMI_SBIN/cp-retrieve-connect-jars.sh $csrc 2>&1 | tee -a /tmp/cp-retrieve-connect-jars.err 
            - |2
                done 
            - |
              fi
            - |+

            - |
              ## [ OPTIONAL ] Open up ssh to allow direct login
            - >
              #sed -i 's/ChallengeResponseAuthentication
              .*no$/ChallengeResponseAuthentication yes/' /etc/ssh/sshd_config
            - |
              #service sshd restart
            - |+

            - >
              ## If all went well, signal success (must be done by ALL nodes in
              group)
            - cfn-signal -e 0 -r 'Confluent Platform node deployment complete' '
            - !Ref NodesReadyHandle
            - |
              '
            - |+

            - |
              ## Wait for all nodes to issue the signal
            - |
              $AMI_SBIN/wait-for-resource.sh NodesReadyCondition 
            - |+

            - >
              ## Signal back information for outputs (now that all nodes are
              up) 
            - $AMI_SBIN/post-cp-info.sh '
            - !Ref ClusterInfoHandle
            - |
              '
            - |+

            - |
              ZOOKER_PORT="2181"
            - |+

            - |
              KAFKA_BROKER_PORT="9092"
            - |+

            - |
              ZOOKEEPER_SERVERS=""
            - |+

            - |
              KAFKA_BROKER_SERVERS=""
            - |+

              read -ra brokerips <<< $(cat /tmp/brokers | cut -d' ' -f1)
            - |+

            - |
              for brokerip in "${brokerips[@]}"; do
            - |2
                KAFKA_BROKER_SERVERS="${brokerip}:${KAFKA_BROKER_PORT} ${KAFKA_BROKER_SERVERS}"
            - |2
              done

              read -ra zookerips <<< $(cat /tmp/zookeepers | cut -d' ' -f1)
            - |+

            - |
              for zookeeperip in "${zookerips[@]}"; do
            - |2
                ZOOKEEPER_SERVERS="${zookeeperip}:${ZOOKER_PORT} ${ZOOKEEPER_SERVERS}"
            - |2
              done


            - |+

            - |
            - KAFKATOPIC_REPLICATIONFACTOR=
            - !Ref KafkaTopicReplicationFactor
            - |+

            - KAFKATOPIC_PARTITIONS=
            - !Ref KafkaTopicPartitions
            - |+

            - KAFKA_TOPIC=
            - !Ref KafkaTopic
            - |+

            - WORKER_TYPE=
            - !Ref NodeType
            - |+

            - LOG_GROUP_NAME=
            - !Ref LogGroupName
            - |+

            - |
            - Env=
            - !Ref Env
            - |+

            - |
            - region=
            - !Ref 'AWS::Region'
            - |+

            - |
              /opt/confluent-5.0.0/bin/kafka-topics --if-not-exists --create --zookeeper $ZOOKEEPER_SERVERS --replication-factor "$KAFKATOPIC_REPLICATIONFACTOR" --partitions "$KAFKATOPIC_PARTITIONS" --topic "$KAFKA_TOPIC"
            - |+

            - |
              if [ "$WORKER_TYPE" = "consumer-worker" ] ; then 
            - |2
                wget https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/amd64/latest/amazon-cloudwatch-agent.rpm
            - |2
                rpm -U ./amazon-cloudwatch-agent.rpm
            - |2
                echo '{
                "agent": {
                        "run_as_user": "cwagent"
                          },
                "logs": {
                        "logs_collected": {
                                "files": {
                                        "collect_list": [
                                                {
                                                        "file_path": "/var/log/groundstation.log",
                                                        "log_group_name": "'$LOG_GROUP_NAME'",
                                                        "log_stream_name": "{instance_id}"
                                                }
                                                        ]
                                          }
                                          }
                        }
              }' > /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json
            - |2
                /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json -s
            - |2
                echo "/opt/aws/amazon-cloudwatch-agent/logs/amazon-cloudwatch-agent.log {
                  missingok
                  notifempty
                  rotate 10
                  daily
                  compress
                  }" > /etc/logrotate.d/cloudwatch-agent
            - |2
                /opt/confluent-5.0.0/bin/kafka-console-consumer --bootstrap-server "$KAFKA_BROKER_SERVERS" --topic "$KAFKA_TOPIC" >> /var/log/groundstation.log
            - |
              fi
            - |+

            - |
              if [ "$WORKER_TYPE" = "producer-worker" ] ; then 
            - |2
                sudo yum update -y
            - |2
                sudo yum groupinstall "Development Tools" -y
            - |2
                sudo yum install git cmake -y
            - |2
                git clone https://github.com/EliasOenal/multimon-ng
            - |2
                cd multimon-ng/
            - |2
                mkdir build
            - |2
                cd build/
            - |2
                cmake ..
            - |2
                make
            - |2
                sudo make install
            - |2
                cd ~
            - |2
                while true; do sudo nc -l 7355 | multimon-ng -a MORSE_CW -t raw - | sudo /opt/confluent-5.0.0/bin/kafka-console-producer --broker-list $KAFKA_BROKER_SERVERS --topic $KAFKA_TOPIC; done &
            - |
              fi
            - |+

            - |
              if [ "$WORKER_TYPE" = "broker" ] ; then
            - |2
                aws ssm put-parameter --name "/${Env}/bootstrap_servers" --value "$KAFKA_BROKER_SERVERS" --type "String" --description "list of brokers" --overwrite --region "$region"
            - |2
                aws ssm put-parameter --name "/${Env}/topic" --value "$KAFKA_TOPIC" --type "String" --description "Kafka topic" --overwrite --region "$region"
            - |
              fi
            - |+
